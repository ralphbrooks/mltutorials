{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413709a3-f49e-43ff-81e0-f6edc340a7ad",
   "metadata": {},
   "source": [
    "# Sentence Classification of Security Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80fa3ab-912a-4f70-8053-3827ec04e67a",
   "metadata": {},
   "source": [
    "This approach examines how to classify whether questions relate to security or if they refer to the installation of doors or windows. \n",
    "\n",
    "The approach produces a classifier with good accuracy that takes between 0.1 and 0.2 seconds to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c316ac-7255-44a7-ac94-8c85b2bef86a",
   "metadata": {},
   "source": [
    "# Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4db061-49f1-4a28-b1b5-92cff1f6f5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d47d4-eb16-431f-bbe9-e3b2cd266f4c",
   "metadata": {},
   "source": [
    "MTEB is the Massive Text Embeddings Benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652159ee-fb57-4c24-af8c-a7e2eb77b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mteb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7873d-3c21-4a06-aede-5fed616dfad0",
   "metadata": {},
   "source": [
    "<b>Datasets</b>\n",
    "\n",
    "Datasets is a library created by Hugging Face that is useful for easily accessing datasets for NLP tasks. \n",
    "\n",
    "\n",
    "Datasets is a requirement for the mteb package. On my system, I just found it was easier to make sure that this package was installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ad0f6-d23b-471e-bb1b-120631837e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d266d616-0298-4af7-9d5f-a56995e2269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6cb898-09fa-4f04-b7ac-6c7c5058f264",
   "metadata": {},
   "source": [
    "## MTEB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08865c31-4752-40e4-a770-56fbb970b809",
   "metadata": {},
   "source": [
    "1) download MTEB\n",
    "2) use embeddings with classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e0e6a-c7cd-45bb-bdc1-bfcb610a2193",
   "metadata": {},
   "source": [
    "https://github.com/embeddings-benchmark/mteb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d00d44-50d3-494f-b8b3-bbd9ad7ab4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteb import MTEB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92a89e-49db-4f7c-8124-c65e41f73eee",
   "metadata": {},
   "source": [
    "# General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1160c6-6949-427d-9234-de3381e1cd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd85aa80-929e-4353-8953-82849838049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw/maincode\")\n",
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw/maincode/api\")\n",
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw\")\n",
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw/maincode/api/wocg/classifiers/security\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29524d04-b292-4912-b776-04b06beca78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import util as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9ce988-b740-4d24-abeb-fb594d9ba9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import denseencoder as de"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f210831-d113-49d4-9a8f-3e33c5078a10",
   "metadata": {},
   "source": [
    "## Collect sentences for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340a1305-1ee2-46eb-8658-50b7ef10ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79618683-b4a5-445e-878e-d1d6e5971c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a84f4dd-9ffd-48c4-a1fe-b03b5c659bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "963cb13a-85ef-4fb9-b48c-bf81d20d907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3acc9a60-88de-4f47-9ea5-cedc7e2fa48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_and_door_questions = [\n",
    "    \"What kind of warranties does SEDW offer on window installation?\",\n",
    "    \"What kinds of Flush Doors does Barnett Millworks offer?\",\n",
    "    \"I am finishing a door. List out for me the SEDW process for doing this.\",\n",
    "    \"I am an employee at SEDW. How long do I have to wait until I get health insurance?\",\n",
    "    \"I want to understand more about the performance of Andersen Multiglide doors. Can you put together a markdown table for me that gives a comparison of Traditional Alum-Clad Wood Non-Thermal vs Contemporary Alum-Class Wood Thermally controlled. These categories as columns and I want to see configuration, Sill Type, Design Pressure, and Water Test Pressure as rows?\",\n",
    "    \"Put together a markdown table for AAN3218, AA32110, AAN3428, and AAN3830. I want the columns for this table to be clear opening area, glass area, and overall window area.\",\n",
    "    \"provide a QAC for remodel / replacement jobs\",\n",
    "    \"list the items on our Quality Assurance Checklist\",\n",
    "    \"can an employee take what looks like extra product from a job and keep it for personal use?\",\n",
    "    \"can i pay for lunch with the company credit card?\",\n",
    "    \"Who does What at Sedw?\",\n",
    "    \"what are the procedures to fix the zebra label printer\",\n",
    "    \"what does anodized mean?\",\n",
    "    \"what are the types of door stops offered by emtek?\",\n",
    "    \"what is a good neck stop?\",\n",
    "    \"explain door handing\",\n",
    "    \"is there a document that shows images or examples of door handing\",\n",
    "    \"what's the difference in an outswing door and an inswing door\",\n",
    "    \"what are muntin bars?\",\n",
    "    \"what is a sash?\",\n",
    "    \"what is multi-point hardware?\",\n",
    "    \"what hardware finishes are available for andersen series 400 windows?\",\n",
    "    \"you provided 7 finishes. there should be a total of 12 finishes available.\",\n",
    "    \"what is an extension jamb?\",\n",
    "    \"When I am checking acknowledgements (for a new construction project) to ensure orders are accurate, what should I check for?\",\n",
    "    \"what information / documents should I use to accomplish this?\",\n",
    "    \"what type of documents would I use to accomplish this?\",\n",
    "    \"what should I check for when reviewing new construction project documents?\",\n",
    "    \"What are the most common window frame materials used by Andersen?\",\n",
    "    \"How do I properly measure for a replacement window?\",\n",
    "    \"What tools do I need for installing a pre-hung exterior door?\",\n",
    "    \"What is the warranty on Milgard vinyl windows?\",\n",
    "    \"How do I clean vinyl window frames?\", \n",
    "    \"What is the best way to weatherproof doors and windows?\",\n",
    "    \"How often should I lubricate and adjust sliding patio doors?\",\n",
    "    \"What is the proper installation method for bay and bow windows?\",\n",
    "    \"What is the maximum recommended window screen size for Andersen casement windows?\",\n",
    "    \"What is the best way to repair fogged double pane windows?\",\n",
    "    \"How do I adjust self-closing door hinges?\",\n",
    "    \"What is the proper installation clearance for fire rated doors?\",\n",
    "    \"What are signs that a wood door may be warped and need replacement?\",\n",
    "    \"How do I fill gaps between window frames and siding?\",\n",
    "    \"What are the most energy efficient styles of windows?\",\n",
    "    \"How do I remove paint from door hinges?\",\n",
    "    \"What are the tools needed for installing a storm door?\",\n",
    "    \"What are the benefits of using foam insulation around windows?\",\n",
    "    \"How do I fix a sticky door lock?\",\n",
    "    \"What maintenance is required for steel entry doors?\",\n",
    "    \"What are the signs of failing weather stripping on doors?\",\n",
    "    \"How do I remove scratches from a glass shower door?\",\n",
    "    \"What is the proper installation method for sliding barn doors?\",\n",
    "    \"How do I repair torn window screens?\",\n",
    "    \"What are the best practices for painting exterior doors?\",\n",
    "    \"How often should patio door rollers be cleaned and lubricated?\",\n",
    "    \"What causes condensation between patio door panes?\",\n",
    "    \"How do I fix a crooked door that sticks?\",\n",
    "    \"What are signs that a door threshold needs to be replaced?\",\n",
    "    \"How do I fix a double hung window that is hard to open?\",\n",
    "    \"What is the proper procedure for removing old windows?\"\n",
    "]\n",
    "\n",
    "\n",
    "document_security_questions = [\n",
    "    \"List all of the users in the system.\",\n",
    "    \"Use the GCP API to list all of the users in the system.\",\n",
    "    \"Add Christina Hoelscher with email christina@yahoo.com to the system.\",\n",
    "    \"How to manage user permissions?\",\n",
    "    \"Is christina@yahoo.com in the system?\",\n",
    "    \"Use the GCP API to add the role installer to the document named a-series-brochure.pdf\",\n",
    "    \"Remove christina@yahoo.com from the system.\",\n",
    "    \"Use the GCP API to remove ralph.a.brooks@gmail.com from the system\",\n",
    "    \"What roles does bob@andersen.com have?\",\n",
    "    \"Add the accounting role to jane@fbook.com .\",\n",
    "    \"Remove the warehouse role from sally@oregonwindows.com.\", \n",
    "    \"List all of the documents in the system.\",\n",
    "    \"List all of the documents in the system that have a filename that starts with warranty.\",\n",
    "    \"Add the role clerical to the document named sedw-companypolicies2017-12-27.pdf\",\n",
    "    \"Remove the role support from the document named support-instructions.pdf\",\n",
    "    \"What is the process for granting access to new documents?\",\n",
    "    \"How do I check who has access to a specific document?\",  \n",
    "    \"Can you provide a list of users with editor access to the document project-plans.docx?\",\n",
    "    \"How do I remove a document from the system?\",\n",
    "    \"What user management features does the system provide?\",\n",
    "    \"How are user permissions managed?\",\n",
    "    \"List all users with viewer access to the document quarterly-financials.xlsx\",\n",
    "    \"How do I add a new user to the system?\",  \n",
    "    \"What authorization levels are available for users?\",\n",
    "    \"How do I change a user's authorization level?\",\n",
    "    \"List all documents that user john@company.com has editor access to\",\n",
    "    \"How do I revoke a user's access to the system?\",\n",
    "    \"What auditing capabilities does the system have for user actions?\",\n",
    "    \"Provide a list of users who have downloaded the document acme-prospectus.pdf in the past week\",\n",
    "    \"How are documents uploaded into the system?\",\n",
    "    \"What metadata is stored for each document?\",  \n",
    "    \"List all documents modified by user jane@company.com in the past month\",\n",
    "    \"How do I change ownership of a document?\",\n",
    "    \"What reports are available on user activity and access?\",\n",
    "    \"Provide a list of users who have viewer access to documents containing the keyword 'financial'\",\n",
    "    \"How are system permissions managed?\",\n",
    "    \"What authentication methods are supported?\",\n",
    "    \"List all documents that user bob@company.com has downloaded in the past month\",\n",
    "    \"How do I reset a user's password?\",\n",
    "    \"What options are available for creating user groups?\",\n",
    "    \"Provide a list of users with editor access to documents containing the keyword 'contract'\",\n",
    "    \"How do I create a new role in the system?\",\n",
    "    \"What default roles exist?\",\n",
    "    \"List all documents that the HR role has editor access to\", \n",
    "    \"How do I remove a role from the system?\",\n",
    "    \"What user audit logging does the system perform?\",\n",
    "    \"Provide a list of roles that have access to the document budget-presentation.pptx\",\n",
    "    \"How do I edit role permissions?\",\n",
    "    \"What reports are available on role activity?\",\n",
    "    \"List all roles that have viewer access to documents owned by user sally@company.com\",\n",
    "    \"Can you explain how the system handles authentication?\",\n",
    "    \"What protocols are supported for integrating with identity providers?\",\n",
    "    \"List all documents accessed by users authenticated via social login in the past month\",\n",
    "    \"Provide a list of documents that contain sensitive financial keywords\",\n",
    "    \"How do I configure restricted access settings for sensitive documents?\",\n",
    "    \"What reporting exists for suspicious access attempts?\",\n",
    "    \"List all failed login attempts in the past 24 hours\",\n",
    "    \"can you check this document? 400-series-brochure.pdf\",\n",
    "    \"give me a summary of the contents in 400-series-brochure.pdf\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c32a748-e870-4030-80a0-863805ff61c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 59)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(window_and_door_questions), len(document_security_questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be9da56-1d7d-45de-9c62-ce162358c0e0",
   "metadata": {},
   "source": [
    "A leaderboard of text embeddings is hosted by Hugging Face. The leaderboard uses the Massive Text Embedding Benchmark. https://huggingface.co/spaces/mteb/leaderboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e8df6-c502-48a4-91f7-040c48996020",
   "metadata": {},
   "source": [
    "# e5-small-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98f7cf7-e439-464a-ad51-ef3f6c6da1bb",
   "metadata": {},
   "source": [
    "e5 uses contrastive pre-training with weak supervision. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a4707-7ef8-4d81-a194-f37cbcec3125",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/2212.03533v1.pdf - Paper that discusses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20655584-817e-4767-9138-7428010356fe",
   "metadata": {},
   "source": [
    "* e5-small-v2 has 12 layers and has a embedding size of 384. \n",
    "\n",
    "https://huggingface.co/intfloat/e5-small-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27146e0-c284-496c-b428-890f23b35657",
   "metadata": {},
   "source": [
    "I thought that e5 could deal with 512 tokens to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8483f448-e3ac-4678-8235-aed35a5c44a5",
   "metadata": {},
   "source": [
    "# e5-small-v2 (0.13 GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17025e3b-28f3-4997-a3ef-8b68ee228885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb637da-0287-4610-b449-8bdf76086900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17aaed6efd024302bb77d3d694319c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64552c1e87fb4dbc8857fbd4e68aac66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e83882024694bc7b337dd5bc36317e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5e4a962763463b87e46e1791bbcb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is an example of how the tokenizer is created. In the remaining part of the code, this is part of the DenseEncoder class.\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/e5-small-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7f32c5-061f-4b22-8df4-5cc6a855fe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3241ed32279f442389391263b825f66b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae82f914dac4b9c8ffa14590ba1922d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# This is an example of how the encoder is created from the pretrained model. \n",
    "# In the remaining part of the code, this will be part of the DenseEncoder class.\n",
    "\n",
    "encoder = AutoModel.from_pretrained('intfloat/e5-small-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7b84f-5d19-42a0-9714-2515d9a9d182",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c5ae3b-c553-4635-95ce-f024e38d325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "294c1334-6209-4665-9222-afdb55e331f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02cd9984-3d88-4f15-89bd-318172420d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9188b69c-8ad6-4fb6-96bf-00446a5f9d11",
   "metadata": {},
   "source": [
    "Logistic Regression (LogisticRegression):\n",
    "\n",
    "Purpose: Used for classification tasks. It estimates the probability that a given instance belongs to a particular category.\n",
    "Equation: Uses the logistic function to squeeze the output of a linear equation between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c815a-ace0-41f8-86b1-f4e32b0dbbf0",
   "metadata": {},
   "source": [
    "Logisitic regression makes use of the sigmoid function which is:\n",
    "\n",
    "$$\n",
    "P(y = 1 | x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}\n",
    "$$\n",
    "\n",
    "where $b_0$ represents the log odds outcome when all of the predictor variables are 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bf2a3be-c403-4aa2-a2c2-f00778bf1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_clf = LogisticRegression(\n",
    "    max_iter=100, \n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f16a9d4-3055-41f6-8fd5-2007a67fbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to predict if we are getting a general question (0) or a question about security (1)\n",
    "all_questions = window_and_door_questions + document_security_questions\n",
    "all_labels = [0]*len(window_and_door_questions) + [1]*len(document_security_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92a90819-9577-42fe-a649-504b4c68a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_question_ids = list(range(len(all_questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7a5f5eb-b031-4868-8fb1-52ccd5334588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to learn on 80% of the examples\n",
    "train_ids, test_ids = train_test_split(all_question_ids, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "212514f2-a4b8-4114-85e5-c6b9757b975c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 24)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f161c73d-21d9-4169-8c32-113f643d84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train = [all_questions[i] for i in train_ids]\n",
    "y_train = [all_labels[i] for i in train_ids]\n",
    "sentences_test = [all_questions[i] for i in test_ids]\n",
    "y_test = [all_labels[i] for i in test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ca2a6c6-d421-4ca8-b74a-93a488fef68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 94, 24, 24)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_train), len(y_train), len(sentences_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a0b1596-336d-43a6-aaf6-a9e9e8b3233f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are signs that a door threshold needs to be replaced?',\n",
       " 'What metadata is stored for each document?',\n",
       " 'I want to understand more about the performance of Andersen Multiglide doors. Can you put together a markdown table for me that gives a comparison of Traditional Alum-Clad Wood Non-Thermal vs Contemporary Alum-Class Wood Thermally controlled. These categories as columns and I want to see configuration, Sill Type, Design Pressure, and Water Test Pressure as rows?',\n",
       " 'What are the benefits of using foam insulation around windows?',\n",
       " 'what type of documents would I use to accomplish this?',\n",
       " 'can you check this document? 400-series-brochure.pdf',\n",
       " 'Remove the warehouse role from sally@oregonwindows.com.',\n",
       " 'Who does What at Sedw?',\n",
       " 'List all documents modified by user jane@company.com in the past month',\n",
       " 'Remove the role support from the document named support-instructions.pdf']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1214fa10-f4fa-4749-9f39-dce250704209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 1, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "887c0061-f685-4fff-849a-39205631ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where is the formal definition for model encode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f8f6e3-6c1f-4a61-91c6-b9c621155b51",
   "metadata": {},
   "source": [
    "### Logic for encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea1296e1-1eaa-43e6-932f-02bec87545a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'denseencoder' from '/home/scott/whiteowlconsultinggroup/cust/sedw/maincode/api/wocg/classifiers/security/denseencoder.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(de)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a840c-27a4-4e06-8261-49f683cb2f6b",
   "metadata": {},
   "source": [
    "#### Brief explanation of DenseEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "166a93dc-9e3c-4e13-a77d-e3c3bf615987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9909daef-53a8-497b-8f52-bbed961d5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sentences_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d0bb3b5-711d-4643-af1a-bf16504d075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, DataCollatorWithPadding, PreTrainedTokenizerFast, BatchEncoding\n",
    "from typing import List, Dict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d445734e-2601-4873-81de-49bd4474a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: Dataset = Dataset.from_dict({'input_texts': sentences})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0bfe73ff-6107-43a1-9511-65e81423bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard coded args\n",
    "prompt = \"query: \"\n",
    "pool_type = \"avg\"\n",
    "l2_normalize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2db700e-ba5e-4e5c-b011-83fbb538b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8443a8c-2afe-4dc1-86c3-3117da1dfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transform function applies the tokenizer. \n",
    "\n",
    "def _transform_func(tokenizer: PreTrainedTokenizerFast,\n",
    "                    examples: Dict[str, List]) -> BatchEncoding:\n",
    "    \"\"\"\n",
    "    Use the tokenizer associated with the model to encode the sentences.\n",
    "    \"\"\"\n",
    "    if prompt:\n",
    "        examples['input_texts'] = [prompt + t for t in examples['input_texts']]\n",
    "\n",
    "    # Take in the sentences. Pad them to the max length of 512. Then truncate them to 512.\n",
    "    batch_dict = tokenizer(examples['input_texts'],\n",
    "                           max_length=512,\n",
    "                           padding=True,\n",
    "                           truncation=True)\n",
    "\n",
    "    return batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06ce0e67-68b2-44db-bb67-fb5cf2d1efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"intfloat/e5-small-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6657f4e6-701a-4510-be3a-40c8962e3b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "atokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6136e3bb-bc75-4137-95e3-dfecb2c65ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is a partial completion of the transform function with the tokenizer\n",
    "dataset.set_transform(partial(_transform_func, atokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42fd4b46-0a03-4d69-9ca1-82d9b9bf76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(atokenizer, pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a123684-0d12-46aa-bf35-fb9e62e2c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43aa32a6-4759-45e1-9271-cca94ab0ef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 128 on the GPU or one on the CPU\n",
    "effective_batch_size = max(1, 128 * gpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2db1ecb0-4bd1-458b-adfb-366e96a8e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=effective_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=2,\n",
    "    collate_fn=data_collator,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73b6dc66-b0c0-4c16-b68f-d5a3003075b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_embeds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8ef2ada-b7c1-414b-a70d-e5fe7f70e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "batch_dict = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b958fc50-ed29-4cd3-8a77-f25fcb0e0f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "64933322-ca1a-4ed2-821d-a658e18e582a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('input_ids', tensor([[  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "        [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "        [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "        [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "        [  101, 23032,  1024,  ...,     0,     0,     0]])), ('token_type_ids', tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])), ('attention_mask', tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdbc2844-83f1-4323-b769-8c73da321b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take everything in the batch and place it on the GPU\n",
    "batch_dict = {k: v.to(device) for k, v in batch_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a1dacd3-af3e-4955-8a1d-d825c1dc340b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "         [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "         [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "         [  101, 23032,  1024,  ...,     0,     0,     0],\n",
       "         [  101, 23032,  1024,  ...,     0,     0,     0]], device='cuda:0'),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27181247-3094-4e65-8d13-4685867ddcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e00fb4a-9338-4c65-bae5-f7d84a495c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import BaseModelOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5e75192-819b-44b0-a192-63efc4770ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs: BaseModelOutput = encoder(**batch_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e922f913-cf1f-4c08-8666-4462b9865801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21886054-6d7e-402c-a845-265a327b1c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.3201,  0.1162,  0.3590,  ...,  0.1849, -0.0870,  0.3112],\n",
       "         [-0.4252,  0.2681,  0.5117,  ...,  0.1928, -0.1562,  0.4421],\n",
       "         [-0.4626,  0.2505,  0.5180,  ...,  0.2261, -0.1439,  0.5052],\n",
       "         ...,\n",
       "         [-0.6241,  0.3687,  0.5437,  ...,  0.3185, -0.2880,  0.4295],\n",
       "         [-0.6291,  0.3671,  0.5468,  ...,  0.3206, -0.2975,  0.4136],\n",
       "         [-0.3198,  0.1164,  0.3589,  ...,  0.1845, -0.0870,  0.3114]],\n",
       "\n",
       "        [[-0.4048,  0.1326,  0.3024,  ...,  0.1842, -0.0558,  0.2753],\n",
       "         [-0.3959,  0.3549,  0.2270,  ...,  0.2509,  0.1121,  0.4615],\n",
       "         [-0.4324,  0.3416,  0.2218,  ...,  0.2357,  0.1719,  0.5027],\n",
       "         ...,\n",
       "         [-0.5038,  0.4114,  0.3261,  ...,  0.1328,  0.2192,  0.5432],\n",
       "         [-0.5051,  0.4052,  0.3402,  ...,  0.1590,  0.2244,  0.5482],\n",
       "         [-0.4927,  0.4033,  0.3281,  ...,  0.1604,  0.1894,  0.5238]],\n",
       "\n",
       "        [[-0.3173,  0.0634,  0.2716,  ...,  0.1602, -0.2058,  0.2507],\n",
       "         [-0.6162,  0.0627,  0.1128,  ...,  0.3749, -0.3926,  0.6313],\n",
       "         [-0.6062,  0.0636,  0.1319,  ...,  0.3284, -0.4132,  0.6935],\n",
       "         ...,\n",
       "         [-0.8120,  0.2333,  0.1773,  ...,  0.3658, -0.3241,  0.5666],\n",
       "         [-0.8026,  0.2307,  0.1851,  ...,  0.3761, -0.3175,  0.5607],\n",
       "         [-0.7290,  0.2079,  0.1589,  ...,  0.3134, -0.3720,  0.4785]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4453,  0.0862,  0.0435,  ...,  0.1086, -0.1584,  0.2232],\n",
       "         [-0.5602,  0.3397, -0.0682,  ...,  0.3960, -0.2840,  0.3048],\n",
       "         [-0.6001,  0.3427, -0.0406,  ...,  0.3750, -0.3053,  0.3695],\n",
       "         ...,\n",
       "         [-0.7257,  0.2644,  0.1197,  ...,  0.2657, -0.4089,  0.3601],\n",
       "         [-0.7410,  0.2618,  0.1309,  ...,  0.2993, -0.4006,  0.3309],\n",
       "         [-0.7677,  0.2614,  0.1180,  ...,  0.2892, -0.3695,  0.3241]],\n",
       "\n",
       "        [[-0.2730,  0.1140,  0.3879,  ...,  0.1718, -0.1019,  0.1859],\n",
       "         [-0.4298,  0.4094,  0.7875,  ...,  0.3687, -0.2662,  0.3692],\n",
       "         [-0.4544,  0.4075,  0.8114,  ...,  0.3865, -0.2466,  0.4040],\n",
       "         ...,\n",
       "         [-0.6631,  0.3433,  0.6819,  ...,  0.4519, -0.4470,  0.3186],\n",
       "         [-0.6682,  0.3472,  0.6973,  ...,  0.4746, -0.4435,  0.3282],\n",
       "         [-0.6573,  0.3583,  0.7108,  ...,  0.4876, -0.4730,  0.3161]],\n",
       "\n",
       "        [[-0.3613,  0.0321,  0.0502,  ...,  0.0955,  0.0324,  0.4253],\n",
       "         [-0.6473,  0.1435, -0.0347,  ...,  0.0298, -0.1396,  0.7175],\n",
       "         [-0.6184,  0.2627,  0.0215,  ...,  0.0478, -0.2861,  0.8265],\n",
       "         ...,\n",
       "         [-0.8165,  0.2056,  0.0994,  ...,  0.2060, -0.1537,  0.7512],\n",
       "         [-0.8414,  0.2230,  0.1135,  ...,  0.2325, -0.1660,  0.7320],\n",
       "         [-0.3608,  0.0325,  0.0502,  ...,  0.0949,  0.0322,  0.4258]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.0498,  0.0417, -0.0217,  ..., -0.0037, -0.0950, -0.0795],\n",
       "        [-0.0447,  0.0314, -0.0085,  ...,  0.0003, -0.0543, -0.0784],\n",
       "        [-0.0535,  0.0033, -0.0013,  ..., -0.0305, -0.0363, -0.0543],\n",
       "        ...,\n",
       "        [-0.0422,  0.0077, -0.0384,  ...,  0.0132, -0.0636, -0.0631],\n",
       "        [-0.0448, -0.0027, -0.0124,  ...,  0.0276, -0.0819, -0.0529],\n",
       "        [-0.0665,  0.0241, -0.0355,  ...,  0.0021, -0.0472, -0.0906]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "73532d73-bf7c-4298-9c7e-08ee3fd347bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3201,  0.1162,  0.3590,  ...,  0.1849, -0.0870,  0.3112],\n",
       "         [-0.4252,  0.2681,  0.5117,  ...,  0.1928, -0.1562,  0.4421],\n",
       "         [-0.4626,  0.2505,  0.5180,  ...,  0.2261, -0.1439,  0.5052],\n",
       "         ...,\n",
       "         [-0.6241,  0.3687,  0.5437,  ...,  0.3185, -0.2880,  0.4295],\n",
       "         [-0.6291,  0.3671,  0.5468,  ...,  0.3206, -0.2975,  0.4136],\n",
       "         [-0.3198,  0.1164,  0.3589,  ...,  0.1845, -0.0870,  0.3114]],\n",
       "\n",
       "        [[-0.4048,  0.1326,  0.3024,  ...,  0.1842, -0.0558,  0.2753],\n",
       "         [-0.3959,  0.3549,  0.2270,  ...,  0.2509,  0.1121,  0.4615],\n",
       "         [-0.4324,  0.3416,  0.2218,  ...,  0.2357,  0.1719,  0.5027],\n",
       "         ...,\n",
       "         [-0.5038,  0.4114,  0.3261,  ...,  0.1328,  0.2192,  0.5432],\n",
       "         [-0.5051,  0.4052,  0.3402,  ...,  0.1590,  0.2244,  0.5482],\n",
       "         [-0.4927,  0.4033,  0.3281,  ...,  0.1604,  0.1894,  0.5238]],\n",
       "\n",
       "        [[-0.3173,  0.0634,  0.2716,  ...,  0.1602, -0.2058,  0.2507],\n",
       "         [-0.6162,  0.0627,  0.1128,  ...,  0.3749, -0.3926,  0.6313],\n",
       "         [-0.6062,  0.0636,  0.1319,  ...,  0.3284, -0.4132,  0.6935],\n",
       "         ...,\n",
       "         [-0.8120,  0.2333,  0.1773,  ...,  0.3658, -0.3241,  0.5666],\n",
       "         [-0.8026,  0.2307,  0.1851,  ...,  0.3761, -0.3175,  0.5607],\n",
       "         [-0.7290,  0.2079,  0.1589,  ...,  0.3134, -0.3720,  0.4785]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4453,  0.0862,  0.0435,  ...,  0.1086, -0.1584,  0.2232],\n",
       "         [-0.5602,  0.3397, -0.0682,  ...,  0.3960, -0.2840,  0.3048],\n",
       "         [-0.6001,  0.3427, -0.0406,  ...,  0.3750, -0.3053,  0.3695],\n",
       "         ...,\n",
       "         [-0.7257,  0.2644,  0.1197,  ...,  0.2657, -0.4089,  0.3601],\n",
       "         [-0.7410,  0.2618,  0.1309,  ...,  0.2993, -0.4006,  0.3309],\n",
       "         [-0.7677,  0.2614,  0.1180,  ...,  0.2892, -0.3695,  0.3241]],\n",
       "\n",
       "        [[-0.2730,  0.1140,  0.3879,  ...,  0.1718, -0.1019,  0.1859],\n",
       "         [-0.4298,  0.4094,  0.7875,  ...,  0.3687, -0.2662,  0.3692],\n",
       "         [-0.4544,  0.4075,  0.8114,  ...,  0.3865, -0.2466,  0.4040],\n",
       "         ...,\n",
       "         [-0.6631,  0.3433,  0.6819,  ...,  0.4519, -0.4470,  0.3186],\n",
       "         [-0.6682,  0.3472,  0.6973,  ...,  0.4746, -0.4435,  0.3282],\n",
       "         [-0.6573,  0.3583,  0.7108,  ...,  0.4876, -0.4730,  0.3161]],\n",
       "\n",
       "        [[-0.3613,  0.0321,  0.0502,  ...,  0.0955,  0.0324,  0.4253],\n",
       "         [-0.6473,  0.1435, -0.0347,  ...,  0.0298, -0.1396,  0.7175],\n",
       "         [-0.6184,  0.2627,  0.0215,  ...,  0.0478, -0.2861,  0.8265],\n",
       "         ...,\n",
       "         [-0.8165,  0.2056,  0.0994,  ...,  0.2060, -0.1537,  0.7512],\n",
       "         [-0.8414,  0.2230,  0.1135,  ...,  0.2325, -0.1660,  0.7320],\n",
       "         [-0.3608,  0.0325,  0.0502,  ...,  0.0949,  0.0322,  0.4258]]],\n",
       "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9349614-097e-40c9-8fb5-ed0dd142f141",
   "metadata": {},
   "source": [
    "- 94 is the number of sentences in sentences_train. It all fits in one batch since it is less than 128.\n",
    "- 56 is the internal sequence length\n",
    "- 384 is the length of the embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0008f90f-a467-474a-991c-96430cc00643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 56, 384])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea46d0c7-dc9a-4ce3-a7c3-fefef39b1ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'avg'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a639a-7577-4890-895b-5879625732c7",
   "metadata": {},
   "source": [
    "When we are loading the data, we are showing where there is no padding with the attention mask>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cec9eff4-b23b-4631-aed2-e1b3d6d9add8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a203ca79-5817-4479-8e43-0a50df812f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 56])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1720b2ff-320c-4728-8827-a38199cfd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fba8c31-9b8a-412f-884d-052f43124bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = batch_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf7e672-86fd-427c-9288-f7f823eb141a",
   "metadata": {},
   "source": [
    "attention_mask[..., None] converts [94, 56] into [94, 56, 1]. It adds an extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd173b1b-d0e3-4617-97f9-e38bdeb0cfd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 56, 1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[..., None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b368d7-7bac-4b26-ae38-67d9dff0650b",
   "metadata": {},
   "source": [
    "Bool converts this into True or Fale Values. ~ is going to invert these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b9cf88f8-bdec-4b8f-9743-aec57bf37844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]],\n",
       "\n",
       "        [[False],\n",
       "         [False],\n",
       "         [False],\n",
       "         ...,\n",
       "         [ True],\n",
       "         [ True],\n",
       "         [ True]]], device='cuda:0')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~attention_mask[..., None].bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f041e745-cff0-47b6-b724-018c81448603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line is simply zeroing out anything where the attention mask is 0 (this is typically padding tokens)\n",
    "last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d98dd842-39e5-4297-8079-30ae3faf0225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 56, 384])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421f6e0-c354-4ce8-b838-ecfcbc729cfd",
   "metadata": {},
   "source": [
    "In this process, I am averaging across the 56 internal dimensions that are produced by E5. \n",
    "I am doing this so that I can get one embedding (length 384) for each of the 94 sentences that I am training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a54d763-10d5-4d64-a0bf-14684505af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum along the internal sequence length. It is a sum of the 56 elements in dimension 1.\n",
    "last_hidden_numerator = last_hidden.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "494f5b78-f62d-45e2-92f7-e50daa96a916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 384])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_numerator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fcbc8a16-a531-45cb-8d04-8d5435db07e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 56])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7125c776-8a26-479a-b61c-324081839559",
   "metadata": {},
   "source": [
    "Summing the attention mask is going to serve as the denominator. It is equivalent the the denominator when computing mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d3062a70-5ea9-4eda-ad63-445aae34eef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask.sum(dim=1)[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24ae7b46-eb34-4330-93fe-0dbc21fca35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing the attention mask allows the average to happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fe2851b-977a-4a23-980d-600b74f44532",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76abec-6430-42e1-a56b-42d084b0bb3b",
   "metadata": {},
   "source": [
    "This now shows that the pooling operation (\"avg\") has been completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5e14911-f1ac-4388-b3a5-f9fe9a2f8503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([94, 384])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74a325d9-2ab1-4e74-8a78-54b4abfb7a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting this all together results in the pool function \n",
    "def pool(last_hidden_states: Tensor,\n",
    "         attention_mask: Tensor,\n",
    "         pool_type: str) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "\n",
    "    if pool_type == \"avg\":\n",
    "        emb = last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "    elif pool_type == \"cls\":\n",
    "        emb = last_hidden[:, 0]\n",
    "    else:\n",
    "        raise ValueError(f\"pool_type {pool_type} not supported\")\n",
    "\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c29f209-0cc1-4fa7-864f-e9e4c7c033fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = pool(outputs.last_hidden_state, batch_dict['attention_mask'], pool_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9035d02-c491-4cf7-9a8e-73b2d64ade37",
   "metadata": {},
   "source": [
    "#### Execution of DenseEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "40796a42-6b18-4ffc-b2b4-5a8016cd7016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cust/sedw/notes/nlp is the combindation of all of the above in the encode part of a custom torch.nn.Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57a6b8ce-b4a4-4fa4-ac0b-29f2043f0559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 20:27:46,235 - MyAppLogger - INFO - Loading model intfloat/e5-small-v2...\n",
      "2024-01-22 20:27:46,889 - MyAppLogger - INFO - GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "model = de.DenseEncoder(\n",
    "    model_name_or_path='intfloat/e5-small-v2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ab9e220-7191-417c-9c0d-827377f2dfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# encode the sentences as embeddings using the e5-small-v2 model\n",
    "X_train = np.asarray(model.encode(sentences_train, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dad2253d-a5c3-4e98-bca7-6dd62ee014d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each embedding contains 384 numbers\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9af1dc38-eeac-48f5-8dd7-0dacd1e6c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e934c1c-789c-4387-923b-09bdaffec193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 384)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a648a9b5-3687-47dc-8518-09f597052f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "X_test = np.asarray(model.encode(sentences_test, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfde3bac-45cb-4440-8221-1b5145f21bcc",
   "metadata": {},
   "source": [
    "X_test represents a holdout of 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "579365a6-d125-4211-bf0e-29b511dc645a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 384)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63c18dff-9ff6-407d-8938-bf62cfd1d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cache = X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae284a-7d07-4f54-847f-037c3a0968ab",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f568b0-50dd-437a-a45c-0c5d7fe753f0",
   "metadata": {},
   "source": [
    "##### Explanation of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "abeff2bf-8462-4a3c-8fb5-c9169d0c5a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51499236,  0.14914134,  0.55764234,  0.08547238, -0.23854885,\n",
       "        0.3037106 ,  0.3354031 , -0.36028975, -0.07882987,  0.10156981,\n",
       "        0.0577091 , -0.26653755, -0.09946077,  0.21468602,  0.2277394 ,\n",
       "       -0.06360664, -0.28164575,  0.7525943 , -0.4986084 ,  0.5038393 ,\n",
       "        0.5938164 , -0.45927   , -0.00303126, -0.7904557 , -0.00307554,\n",
       "        0.48803908,  0.431343  ,  0.54404616, -0.405484  , -1.0808046 ,\n",
       "       -0.48698422, -0.12839562, -0.02057808, -0.23252465,  0.01595651,\n",
       "       -0.44543445,  0.15081415, -0.0349281 ,  0.26383168,  0.14510569,\n",
       "       -0.29242676, -0.5643637 ,  0.20347795, -0.81849635, -0.11122759,\n",
       "       -0.16483097, -0.36363545, -0.410171  ,  0.44259813,  0.0502857 ,\n",
       "       -0.500818  ,  0.03072342,  0.22073905,  0.3136644 ,  0.35880774,\n",
       "       -0.06409074,  0.4261081 ,  0.05246903,  0.39038613,  0.28953096,\n",
       "        0.2384326 ,  0.5947179 , -1.4262769 ,  1.2155329 ,  0.67613673,\n",
       "        0.62881887, -0.2096899 , -0.04804755, -0.14080143,  0.11848652,\n",
       "        0.03048385,  0.3618476 ,  0.02847159,  0.09606937, -0.12597199,\n",
       "        0.6743494 ,  0.03940554,  0.3579614 , -0.48100865, -0.30532753,\n",
       "       -0.15901361, -0.28807843, -0.3109216 ,  0.3602964 ,  0.09548762,\n",
       "       -0.25169325,  0.45559275, -0.16557102, -0.18464947, -0.23977795,\n",
       "       -0.16547975, -0.30002633,  0.26176605, -0.31807455, -0.0805824 ,\n",
       "        0.11961355,  0.38384408, -0.17517966, -0.337808  ,  0.72160405,\n",
       "        0.10625633, -0.21039115, -0.12827343, -0.61000097, -0.07767404,\n",
       "        0.01257152,  0.20987949,  0.04631597,  0.15655194,  0.01014393,\n",
       "       -0.27272135, -0.40090686, -0.44205922, -0.16206877,  0.77723014,\n",
       "        0.04444416, -0.24687897, -0.47070423, -0.30692437,  0.3009769 ,\n",
       "        0.39695576,  0.17109546,  0.20866969, -0.18825725,  0.15409766,\n",
       "       -0.08366646, -0.06498434,  0.31356868,  0.7654943 , -0.09836421,\n",
       "        0.2836495 , -0.31730813, -0.10464664,  0.18480498, -0.19306733,\n",
       "        0.03652555,  0.02971251, -0.1776735 ,  0.30705747, -0.08869302,\n",
       "       -0.5842257 , -0.1672196 , -0.00468021, -0.588411  ,  0.44426978,\n",
       "        0.46232346, -1.0596426 ,  0.33512256, -0.82268995, -0.5500423 ,\n",
       "       -0.31112117,  0.13542724,  0.43140835,  0.08287007,  0.20277056,\n",
       "        0.09483545, -0.31978735,  0.16598561, -0.18824634,  0.30408758,\n",
       "       -0.37815025, -0.23855586,  0.20758457,  1.2181844 ,  0.4486049 ,\n",
       "       -1.2771876 ,  0.56510746, -0.3066594 ,  0.2102399 , -0.36476263,\n",
       "        0.03431786,  0.39318213,  0.1727559 , -0.14702538,  0.9377194 ,\n",
       "       -0.17454953, -0.39000258, -0.3447581 ,  0.23335211,  0.00982318,\n",
       "        0.3137289 , -0.48108223, -0.4860797 ,  0.08638673,  0.65295684,\n",
       "       -0.23266062, -0.21080852, -0.447981  , -0.28562894, -0.18802021,\n",
       "       -0.07610048,  0.29278773,  0.3087731 ,  0.4016492 ,  0.16165629,\n",
       "        0.25985235, -0.17473054, -0.6694365 , -0.5407446 , -0.558277  ,\n",
       "        0.553649  ,  0.4413008 , -0.72664344,  0.01380344, -0.3132354 ,\n",
       "        0.56450343,  0.2607387 , -0.59419054, -0.2955964 , -0.24314019,\n",
       "        0.0510257 , -0.05287631,  0.33140865, -0.60669243, -0.13865359,\n",
       "       -0.3937576 ,  0.242584  ,  0.15250199,  0.17196503,  0.3478867 ,\n",
       "        0.31192157, -0.53357625, -0.12104357, -1.1616834 ,  0.222842  ,\n",
       "       -0.6262971 , -0.3289587 ,  0.7909205 , -0.17932183,  0.01343822,\n",
       "        0.16002665, -0.9462427 ,  0.31907022,  0.7981635 , -0.05858275,\n",
       "       -0.20331706, -0.34220853, -0.07384647,  0.4912686 , -0.5413771 ,\n",
       "       -0.42507055,  0.26291102, -0.03973829, -0.04954501, -0.5267204 ,\n",
       "       -0.7510777 , -0.7289099 ,  0.13241227, -0.53106785,  0.84546024,\n",
       "        0.4145337 ,  0.52556646, -0.45048496,  0.7329928 , -0.17147559,\n",
       "        0.19616269, -0.4907348 ,  0.5050201 , -0.18767984,  0.17481986,\n",
       "        0.8166603 ,  0.22049211, -0.21218711,  0.39360705, -0.07910255,\n",
       "        0.40666753, -0.34358206,  0.99835676, -0.4218487 ,  0.18481398,\n",
       "        0.28691387, -0.19298023, -0.6453858 ,  0.42788365, -0.19320859,\n",
       "        0.5988848 , -0.03774422, -0.35078192, -0.34306878, -0.30833378,\n",
       "        0.5077421 , -0.5285775 ,  0.0522755 , -0.4640229 , -0.27264506,\n",
       "        0.56078136,  0.3342407 , -0.04698646,  0.35937607, -0.32675824,\n",
       "       -0.06092559, -0.04153381, -0.6560516 , -0.2211286 ,  0.44459292,\n",
       "       -0.42867956,  1.044052  ,  0.5548946 ,  0.25139773,  0.33892545,\n",
       "       -0.31654346, -0.13466676, -0.48334447, -0.20530231, -0.8012684 ,\n",
       "        0.34389067,  0.34460813,  0.52012384, -0.4115972 , -0.38532576,\n",
       "       -0.02309026,  0.36787164, -0.20842992,  0.10076575, -0.06734915,\n",
       "        0.58769244,  0.4070545 ,  0.15986533, -0.34282228, -1.0746366 ,\n",
       "       -0.3679629 ,  0.5278706 , -0.13561681,  0.08844347, -0.00754227,\n",
       "        0.3420123 , -0.0841492 ,  0.16549763, -0.5355329 ,  0.07451097,\n",
       "        0.05521518,  0.1375081 , -0.00289539,  0.13461502,  0.05608462,\n",
       "        0.4773578 ,  0.09923708, -0.40848303, -0.7701487 , -0.22595297,\n",
       "        0.49203017,  1.0565169 ,  0.34939778,  0.09801367,  0.34765542,\n",
       "        0.38517934, -0.22403549,  0.12626603,  0.2264659 ,  0.18561497,\n",
       "       -0.24168402,  0.529976  , -0.02333376,  0.7028161 ,  0.5031792 ,\n",
       "       -0.27300173, -0.01757416,  0.12325414, -0.4675888 ,  0.48024458,\n",
       "        0.61910707, -0.12853733, -0.20505646,  0.64320195, -0.23452325,\n",
       "       -0.28549337, -0.1677675 , -0.10995   , -0.19200268, -0.49782974,\n",
       "       -0.10243377,  0.6414063 ,  0.43515924,  0.20663467, -0.36842707,\n",
       "       -0.4092413 , -0.1762961 , -0.49308118, -0.3222838 ,  0.3546671 ,\n",
       "       -0.542351  ,  0.28595603, -0.16745059,  0.46201414], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d272f7e-4def-4a53-a5c4-6ad77979deaa",
   "metadata": {},
   "source": [
    "multi_class is set to 'auto.' As seen in https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html, this means that 'ovr' (One-vs-Rest) approach is going to be used because this is a binary classification. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfacb681-4ba2-4cd1-896a-e5808f073da9",
   "metadata": {},
   "source": [
    "Since this is binary classification, it seems that scikit learn still defaults to binary cross-entropy loss (aka log loss). Cross-entropy loss for single observation is:\n",
    "\n",
    "$\n",
    "Loss = -[y \\log(p) + (1 - y) \\log(1 - p)]\r",
    "$\n",
    "\n",
    "\n",
    "and the average of the individual losses represents the loss function that we are going to use. This is :\n",
    "\n",
    "$$\r\n",
    "-\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\r\n",
    "$$\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992be7ea-6477-4599-bee4-6b29ef3ebb82",
   "metadata": {},
   "source": [
    "In this formula:\n",
    "- $N$ is the number of samples.\n",
    "- $y_i$ is the actual label of the $i$-th sample.\n",
    "- $p_i$ is the predicted probability of the $i$-th sample being in the positive class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d4c21-af19-4965-99d2-9ecf7a93ec81",
   "metadata": {},
   "source": [
    "To illustrate how cross entropy works, lets take a look at a more simple example first. \n",
    "\n",
    "What if we only had 5 data points (instead of the 94)? What if those data points were:\n",
    "\n",
    "$\n",
    "\\begin{align*}\n",
    "1. (x_1, y_1) = (0.5, 0) \\\\\n",
    "2. (x_2, y_2) = (1.5, 0) \\\\\n",
    "3. (x_3, y_3) = (2.5, 1) \\\\\n",
    "4. (x_4, y_4) = (3.5, 1) \\\\\n",
    "5. (x_5, y_5) = (4.5, 1) \\\\\n",
    "\\end{align*}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b97f58-2dc1-4afe-ae8f-95b8bf744604",
   "metadata": {},
   "source": [
    "If we started with a baseline of $b_0$ = 0 and $b_1$ = 1, then the logistic function would be $z = b_0 + b_1x_1$ or $z = 0 + 1 x 0.5. \n",
    "\n",
    "The predicted probability is $$\r\n",
    "p = \\frac{1}{1 + e^{-z}}\r\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7928b7cc-70b0-460a-a56a-82111db207ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted probability \n",
    "import math\n",
    "p = 1 / (1 + math.exp(-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b58ed9ed-4bd1-4995-9d2d-6f527dd8b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224593312018546"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fbb686-fd10-4e46-918b-bef35e50a87e",
   "metadata": {},
   "source": [
    "Go back to the loss function above. Since y is 0 , $\n",
    "Loss = -[y \\log(p) + (1 - y) \\log(1 - p)]\n",
    "$ gets reduced to  $loss = -[log(1-p)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b797f205-2d80-4fcd-a5f5-e24da0fcb222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3775406687981454"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 1-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8f290d8e-60bf-486a-843e-93aa32ee6c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4a7a1abb-a72a-4a38-9665-5c4d6dd6b9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9740769841801068"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(1-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3754aa-40ef-4f62-b00b-53a77e982770",
   "metadata": {},
   "source": [
    "This means that the resulting loss for this observation is: + 0.974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ad882-5754-44b3-af37-bf95722f35f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5f07de-7a1b-423e-bb33-54e4b6aa057d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "233d3e0a-97ec-4cc5-8ebc-c6c0febb575a",
   "metadata": {},
   "source": [
    "Wrapping up this example, each of the other data points would get calculated in the same way to put together the loss function.\n",
    "\n",
    "$$\n",
    "-\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719bbebd-5a96-4e22-903b-1fe4c1fe36ae",
   "metadata": {},
   "source": [
    "Now you need to calculate the gradient of the loss function with respect to each weight and bias. \n",
    "* You want to update the weights and biases in a manner that reduces the loss function.\n",
    "* This is handled with an optimizer. The logistic regression in scikit-learn uses a sophisticated version of gradient decscent.\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daa4282-ce0b-46a8-85c2-a04abec1ee36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e97f2d52-9b1f-403e-9978-021e14724992",
   "metadata": {},
   "source": [
    "##### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e42457d0-bd72-4d75-91b1-bda2fe122aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 384)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec3b9cdd-019f-41b0-808f-7d0f394b89e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =          385     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.93147D-01    |proj g|=  9.87033D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "  385     21     24      1     0     0   8.536D-05   1.031D-01\n",
      "  F =  0.10308827952432373     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(n_jobs=-1, random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(n_jobs=-1, random_state=42, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(n_jobs=-1, random_state=42, verbose=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "24f48fd2-a13f-443b-9e0a-668f147e6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b545fee-b870-409f-bef6-dd9dda7d83bb",
   "metadata": {},
   "source": [
    "Accuracy is the proportion of correct preditions / the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03cbc838-529c-4f61-b424-6122cf275e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bc527-007d-4a54-94d3-965fb8ce81e9",
   "metadata": {},
   "source": [
    "$$ F1 = 2 \\times \\frac{{\\text{precision} \\times \\text{recall}}}{{\\text{precision} + \\text{recall}}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4cba156f-99f5-4ba8-8c14-017b35b33f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9a893-175c-4946-ae2f-e84f54aac061",
   "metadata": {},
   "source": [
    "- Recall is the true positive rate.\n",
    "\n",
    "- Average precision score is looking at \n",
    "$$\n",
    "AP = \\sum_n (R_n - R_{n-1}) P_n\n",
    "$$\n",
    "Where $P_n$ and $R_n$ are the precision and recall at the nth threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c19fc81a-0c2c-4349-b042-0d79db7a293d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515cd23-7b81-4be7-ab09-fdb56496ec0c",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc68c4-f745-443e-a5e4-f2888214ea67",
   "metadata": {},
   "source": [
    "Use pickle in order to save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9a3c3b6e-2a93-4db3-8939-bb855163777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any existing pickle files\n",
    "!rm logistic_clf_model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "057bc805-d59f-4afb-8b7f-058489cacd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to disk\n",
    "with open('logistic_clf_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(logistic_clf, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ca13d31c-c625-4c7d-812a-f807637683d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_clf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# confirm that the pickle file has been created\n",
    "!ls | grep logis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233aa0c-de7b-449d-837d-1a17b0a7e529",
   "metadata": {},
   "source": [
    "## Load and Classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e2654-4fee-4dea-91ca-f8b9ac73e212",
   "metadata": {},
   "source": [
    "Load the model that was saved and use this as a sentence classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f257dfdf-9c32-426a-a8c7-46e72cae76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f5138cf3-04ce-420b-96e5-ce45ec3f6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3ccf21f2-0a37-4284-afdb-1badfce8820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw/maincode\")\n",
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw/maincode/api\")\n",
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw\")\n",
    "sys.path.append(\"/home/scott/whiteowlconsultinggroup/cust/sedw/maincode/api/wocg/classifiers/security\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d614b12-a11f-4c99-8e08-5e1a65cc65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c4abe64a-1707-4359-84fd-cce19446de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import denseencoder as de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4e743139-543f-49aa-87fe-75633c8e261e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'denseencoder' from '/home/scott/whiteowlconsultinggroup/cust/sedw/maincode/api/wocg/classifiers/security/denseencoder.py'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "65d5620c-3873-4c75-ab50-73b2bccd0827",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 20:30:11,156 - MyAppLogger - INFO - Loading model intfloat/e5-small-v2...\n",
      "2024-01-22 20:30:11,971 - MyAppLogger - INFO - GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the logistic regression model\n",
    "with open('logistic_clf_model.pkl', 'rb') as model_file:\n",
    "    loaded_logistic_clf = pickle.load(model_file)\n",
    "\n",
    "# Load the DenseEncoder model\n",
    "loaded_dense_encoder = de.DenseEncoder(model_name_or_path='intfloat/e5-small-v2')\n",
    "loaded_dense_encoder.to_device('cpu')  # Move to CPU\n",
    "\n",
    "def classify_sentence(sentence: str, loaded_model, loaded_encoder_model) -> int:\n",
    "    \"\"\"\n",
    "    Classify the given sentence.\n",
    "    1 if it's a document security question.\n",
    "    0 if it's a window and door question.\n",
    "\n",
    "    Parameters:\n",
    "    sentence (str): The sentence to classify.\n",
    "    model_path (str): The path to the saved logistic regression model.\n",
    "    encoder_model (DenseEncoder): Preloaded DenseEncoder model to use for encoding the sentence.\n",
    "\n",
    "    Returns:\n",
    "    int: The class label.\n",
    "    \"\"\"\n",
    "\n",
    "    # Use the pre-loaded models\n",
    "    logistic_clf = loaded_model\n",
    "    encoder_model = loaded_encoder_model\n",
    "\n",
    "    # Encode the sentence\n",
    "    encoded_sentence = np.asarray(encoder_model.encode([sentence]))\n",
    "\n",
    "    # Predict the class\n",
    "    prediction = logistic_clf.predict(encoded_sentence)\n",
    "\n",
    "    return prediction[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "167a7df9-5abf-4aea-adfa-a41e4f237a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_to_classify = \"What kind of warranties does SEDW offer on window installation?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "697cd9a5-1d2c-449e-84d2-e61acd0d0cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict: 0.1569 seconds\n",
      "The sentence is a window and door question.\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "start_time = time.time()  # Record the start time\n",
    "result = classify_sentence(sentence_to_classify, loaded_model=loaded_logistic_clf, loaded_encoder_model=loaded_dense_encoder)  # model is the existing DenseEncoder instance\n",
    "end_time = time.time()  # Record the end time\n",
    "elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "print(f\"Time taken to predict: {elapsed_time:.4f} seconds\")\n",
    "print(f\"The sentence is a {'document security' if result == 1 else 'window and door'} question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7cb4ee44-8826-4513-9936-dd95b128be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_to_classify = \"List all of the users in the system\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "09ec48f8-5b95-4397-9a32-9ab4b96f1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to predict: 0.1076 seconds\n",
      "The sentence is a document security question.\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "start_time = time.time()  # Record the start time\n",
    "result = classify_sentence(sentence_to_classify, loaded_model=loaded_logistic_clf, loaded_encoder_model=loaded_dense_encoder)  # model is the existing DenseEncoder instance\n",
    "end_time = time.time()  # Record the end time\n",
    "elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "print(f\"Time taken to predict: {elapsed_time:.4f} seconds\")\n",
    "print(f\"The sentence is a {'document security' if result == 1 else 'window and door'} question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbe32d-d742-453f-b2db-10f6e4777029",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
